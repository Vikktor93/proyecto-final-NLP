{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7395a0",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://i.ibb.co/v3CvVz9/udd-short.png\" width=\"150\"/>\n",
    "    <br>\n",
    "    <strong>Universidad del Desarrollo</strong><br>\n",
    "    <em>Magíster en Data Science</em><br>\n",
    "    <em>Profesora: Maria Paz Raveau</em><br>\n",
    "    <em>Asignatura: Procesamiento de Lenguaje Natural</em><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d451bd4",
   "metadata": {},
   "source": [
    "## **Proyecto Final PLN: Sesgo en Word Embeddings (WEAT)**\n",
    "**Curso:** Procesamiento de Lenguaje Natural – Magíster en Data Science UDD (2025) \n",
    "\n",
    "*Fecha de Entrega: Martes 02, Septiembre 2025.*\n",
    "\n",
    "**Estudiantes**: Victor Saldivia Vera, Cristian Tobar, Joaquin Leiva.\n",
    "\n",
    "### **1. Instrucciones y Enunciado**\n",
    "\n",
    "Se ha dicho que los modelos de WordEmbeddings contienen sesgos. Se solicita investigar qué\n",
    "sesgos han sido identificados en la literatura, y buscar al menos una métrica para evaluar alguno de\n",
    "estos sesgos. Testear esta métrica en algunos de los modelos pre-entrenados en idioma\n",
    "español y concluir respecto al sesgo encontrado (o no encontrado). \n",
    "\n",
    "El entregable es un reporte de las siguientes características:\n",
    "\n",
    "- **Introducción** sobre sesgos que han sido identificados en modelos de embeddings *(máximo\n",
    "1200 palabras, 10 puntos)*. Se evaluará el uso de literatura pertinente. Ser informativo:\n",
    "¿Qué sesgo se han identificados?, ¿Qué corpus fue utilizado?, ¿Con qué métricas? En esta sección deberá\n",
    "explicitar que sesgo se eligió para testear, qué métrica y con qué modelo pre-entrenado en\n",
    "español se trabajó. Todo debe estar debidamente referenciado.\n",
    "- **Método:** explicar qué métrica fue utilizada para evaluar la presencia del sesgo. Se debe explicar la\n",
    "métrica, no el código. El código se entregará como anexo y no será necesariamente\n",
    "revisado *(máximo 500 palabras, 5 puntos)*.\n",
    "- **Resultados/Conclusiones:** Reportar los resultados y concluir respecto a la ideonidad\n",
    "de la métrica usada, y a la presencia o no de sesgo en el corpus. ¿Son consistentes sus\n",
    "resultados con los reportados en la literatura? *(700 palabras máximo)*.\n",
    "- Referencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562471c1",
   "metadata": {},
   "source": [
    "### **2. Breve Introducción**\n",
    "En este cuaderno Jupyter se implementa el **Word Embedding Association Test (WEAT)** para evaluar la presencia de sesgos de género en *word embeddings* en español.  \n",
    "\n",
    "Se utiliza como **modelo principal** `fastText` en español (`cc.es.300.vec`) y opcionalmente `SBW` (Spanish Billion Words, word2vec).  \n",
    "\n",
    "El enfoque está en el **sesgo de género** (hombre ↔ carrera vs mujer ↔ familia)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5823a0a2",
   "metadata": {},
   "source": [
    "### **3. Imports y Seeds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d07c5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, zipfile, shutil, json, random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80e01e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07f74a",
   "metadata": {},
   "source": [
    "### **3. Ajustes de Rutas del Proyecto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c485da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raíz del proyecto: C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\n",
      "Embeddings directorio: C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\\data_embeddings\n",
      "Outputs directorio: C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\\outputs\n"
     ]
    }
   ],
   "source": [
    "# Se sube un nivel para llegar a la raíz del proyecto:\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# Carpeta de embeddings y de salidas en la raíz del repositorio\n",
    "DATA_DIR   = PROJECT_ROOT / \"data_embeddings\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "# Se crean las carpetas si no existen\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Raíz del proyecto:\", PROJECT_ROOT)\n",
    "print(\"Embeddings directorio:\", DATA_DIR)\n",
    "print(\"Outputs directorio:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744c249",
   "metadata": {},
   "source": [
    "### **4.  Modelos Pre-entrenados en Español**\n",
    "\n",
    "Para este proyecto utilizamos embeddings **pre-entrenados**, que son vectores generados a partir de grandes corpus de texto.  \n",
    "\n",
    "- **fastText (cc.es.300.vec.gz)** → entrenado en *Common Crawl + Wikipedia*, con 300 dimensiones y subpalabras.  \n",
    "- **SBW word2vec (sbw-300-min5.vec.gz)** → entrenado en *Spanish Billion Words Corpus* (aprox 1.5 Billones de tokens).  \n",
    "\n",
    "*Observaciones:*\n",
    "\n",
    "- *Ambos se deben descargar y colocar en la carpeta `data_embeddings/`*\n",
    "- *El archivo `.gz` se descomprime a `.vec` antes de cargarse con `gensim`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2fdc0",
   "metadata": {},
   "source": [
    "Se crea un `función` de nombre `gunzip` que descomprime un `.gz` a `.vec` (texto). No hace nada si ya existe el `.vec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46df9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descomprimiendo .gz → cc.es.300.vec\n",
      "Listo: C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\\data_embeddings\\cc.es.300.vec\n",
      "Descomprimiendo .zip → C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\\data_embeddings\n",
      "Listo: C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\\data_embeddings\\SBW-vectors-300-min5.txt\n",
      "\n",
      "Resumen:\n",
      " - fastText .vec: True C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\\data_embeddings\\cc.es.300.vec\n",
      " - SBW (Kaggle .txt): True C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\\data_embeddings\\SBW-vectors-300-min5.txt\n",
      " - SBW (legado .vec): False C:\\Users\\victo\\OneDrive\\Documentos\\Programming-2025\\UDD-2025\\NLP\\Proyecto\\data_embeddings\\sbw-300-min5.vec\n"
     ]
    }
   ],
   "source": [
    "# FastText: .gz -> .vec\n",
    "FASTTEXT_VEC_GZ  = DATA_DIR / \"cc.es.300.vec.gz\"\n",
    "FASTTEXT_VEC_TXT = DATA_DIR / \"cc.es.300.vec\"\n",
    "\n",
    "# SBW: puede venir como .zip o .txt.zip\n",
    "# Se busca cualquier zip que empiece con \"SBW-vectors\"\n",
    "SBW_ZIP = None\n",
    "for f in DATA_DIR.glob(\"SBW-vectors*.zip\"):\n",
    "    SBW_ZIP = f\n",
    "    break\n",
    "\n",
    "# Archivo esperado después de descomprimir\n",
    "SBW_VEC_TXT = DATA_DIR / \"SBW-vectors-300-min5.txt\"\n",
    "\n",
    "# (Compatibilidad) SBW legado: .gz -> .vec\n",
    "SBW_VEC_GZ_LEGACY  = DATA_DIR / \"sbw-300-min5.vec.gz\"\n",
    "SBW_VEC_TXT_LEGACY = DATA_DIR / \"sbw-300-min5.vec\"\n",
    "\n",
    "def gunzip(src_gz: Path, dst_txt: Path):\n",
    "    if dst_txt.exists():\n",
    "        print(\"Ya existe:\", dst_txt)\n",
    "        return True\n",
    "    if not src_gz.exists():\n",
    "        print(\"No se encuentra:\", src_gz)\n",
    "        return False\n",
    "    print(\"Descomprimiendo .gz →\", dst_txt.name)\n",
    "    with gzip.open(src_gz, 'rb') as f_in, open(dst_txt, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "    print(\"Listo:\", dst_txt)\n",
    "    return True\n",
    "\n",
    "def unzip(src_zip: Path, expected_txt: Path, dest_dir: Path):\n",
    "    if expected_txt.exists():\n",
    "        print(\"Ya existe:\", expected_txt)\n",
    "        return True\n",
    "    if not src_zip or not src_zip.exists():\n",
    "        print(\"No se encontró el archivo zip:\", src_zip)\n",
    "        return False\n",
    "    print(\"Descomprimiendo .zip →\", dest_dir)\n",
    "    with zipfile.ZipFile(src_zip, 'r') as zf:\n",
    "        zf.extractall(dest_dir)\n",
    "        names = zf.namelist()\n",
    "    if expected_txt.exists():\n",
    "        print(\"Listo:\", expected_txt)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Extraído, pero no se encontro el archivo esperado:\", expected_txt.name)\n",
    "        print(\"Archivos en el zip:\", names[:10], \"... (máximo 10)\")\n",
    "        return False\n",
    "\n",
    "# PROCESO\n",
    "# 1. fastText (.gz → .vec)\n",
    "_ = gunzip(FASTTEXT_VEC_GZ, FASTTEXT_VEC_TXT)\n",
    "\n",
    "# 2. SBW Kaggle (.zip/.txt.zip → .txt)\n",
    "ok_sbw = False\n",
    "if SBW_ZIP:\n",
    "    ok_sbw = unzip(SBW_ZIP, SBW_VEC_TXT, DATA_DIR)\n",
    "\n",
    "# 3. Si no hubo zip Kaggle, intentar legado (.gz → .vec)\n",
    "if not ok_sbw and SBW_VEC_GZ_LEGACY.exists():\n",
    "    ok_sbw = gunzip(SBW_VEC_GZ_LEGACY, SBW_VEC_TXT_LEGACY)\n",
    "\n",
    "print(\"\\nResumen:\")\n",
    "print(\" - fastText .vec:\", FASTTEXT_VEC_TXT.exists(), FASTTEXT_VEC_TXT)\n",
    "print(\" - SBW (Kaggle .txt):\", SBW_VEC_TXT.exists(), SBW_VEC_TXT)\n",
    "print(\" - SBW (legado .vec):\", SBW_VEC_TXT_LEGACY.exists(), SBW_VEC_TXT_LEGACY)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_weat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
